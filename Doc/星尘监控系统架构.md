# 星尘监控系统架构文档

## 1. 概述

星尘（Stardust）是一个轻量级分布式监控平台，为企业提供应用性能监控（APM）能力。系统采用**客户端采样统计 + 服务端多级汇总**的架构，在保证监控精度的同时，大幅降低了网络传输和存储成本。

### 1.1 核心设计理念

与传统 APM 系统（如 SkyWalking、Jaeger）全量采集不同，星尘采用：

| 特性 | 传统 APM | 星尘 |
|------|---------|------|
| 数据采集 | 全量采集，服务端聚合 | 客户端采样+统计，服务端汇总 |
| 网络开销 | 高（每次调用上报） | 低（周期性批量上报统计） |
| 存储压力 | 极高 | 可控 |
| 实时性 | 高 | 分钟级 |

### 1.2 系统定位

- **目标用户**：企业内部部署
- **典型规模**：
  - 应用数量：20~100 个
  - 埋点总数（TraceItem）：几十万个（建议控制在 10 万以内）
  - 单应用埋点数：100~300 个（不建议超过 1000 个）
  - 每日跟踪数据（TraceData）：2000~5000 万行
  - 每日埋点统计调用：10 亿+ 次

---

## 2. 系统架构

### 2.1 整体架构图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              应用层（客户端）                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │   App A     │  │   App B     │  │   App C     │  │   App ...   │        │
│  │  (2实例)    │  │  (3实例)    │  │  (2实例)    │  │             │        │
│  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘        │
│         │                │                │                │               │
│         │     ┌──────────┴────────────────┴────────────────┘               │
│         │     │   StarTracer（每实例一个）                                  │
│         │     │   - 自动埋点：DB/Redis/HTTP/WebAPI                         │
│         │     │   - 周期采样（默认60秒）                                    │
│         │     │   - 本地统计：次数/耗时/错误                                │
│         └─────┴──→ ProcessSpans() 上报                                     │
│                                                                             │
└───────────────────────────────────┬─────────────────────────────────────────┘
                                    │ HTTP POST (JSON/GZip)
                                    │ 每应用每分钟上报一次
                                    │ 每次约50~60个 SpanBuilder
                                    
┌─────────────────────────────────────────────────────────────────────────────┐
│                            服务端（Stardust.Server）                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │                        TraceController                               │   │
│  │  ┌───────────────┐    ┌───────────────┐                             │   │
│  │  │ Report()      │    │ ReportRaw()   │  ← 压缩数据                  │   │
│  │  │ 普通埋点数据  │    │ 大数据量     │                              │   │
│  │  └───────┬───────┘    └───────┬───────┘                             │   │
│  │          └────────────────────┴──────────────┐                       │   │
│  │                                                                     │   │
│  │                              ┌───────────────────────────┐          │   │
│  │                              │       ProcessData()       │          │   │
│  │                              │  1. 过滤异常埋点           │          │   │
│  │                              │  2. GetOrAddItem (?性能)  │          │   │
│  │                              │  3. 生成 TraceData        │          │   │
│  │                              │  4. 生成 SampleData       │          │   │
│  │                              │  5. 批量插入数据库        │          │   │
│  │                              └─────────────┬─────────────┘          │   │
│  └──────────────────────────────────────────────────────────────────────┘   │
│                                              │                              │
│                    ┌─────────────────────────┼─────────────────────────┐    │
│                                                                          │
│  ┌─────────────────────────┐  ┌─────────────────────────┐  ┌────────────┐  │
│  │   TraceStatService      │  │   AppDayStatService     │  │ ItemStat   │  │
│  │   追踪统计服务           │  │   应用天统计服务         │  │ 埋点统计   │  │
│  │   (80%资源占用)         │  │                         │  │            │  │
│  └─────────────────────────┘  └─────────────────────────┘  └────────────┘  │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 数据流向

```
客户端采样周期（60秒）
        │
        
    SpanBuilder[]  ────────────?  TraceController.Report()
    (50~60个/次)                          │
                                          
                                   ┌──────────────┐
                                   │ ProcessData  │
                                   └──────┬───────┘
                                          │
                    ┌─────────────────────┼─────────────────────┐
                                                              
              TraceData              SampleData           统计队列
              (跟踪数据)             (采样数据)            (内存)
              31张分表               31张分表
                    │                     │                     │
                    └─────────────────────┘                     │
                              │                                 │
                    批量INSERT数据库                             │
                              │                                 │
                              └──────────────? TraceStatService
                                                      │
                            ┌─────────────────────────┼─────────────────────────┐
                                                                              
                    ┌──────────────┐         ┌──────────────┐         ┌──────────────┐
                    │  分钟统计     │         │  小时统计     │         │   天统计     │
                    │ (5分钟粒度)  │ ──────? │              │ ──────? │              │
                    │TraceMinuteStat│        │TraceHourStat │         │TraceDayStat  │
                    └──────────────┘         └──────────────┘         └──────────────┘
                            │
                            
                    ┌──────────────┐
                    │ 应用分钟统计  │
                    │AppMinuteStat │ ──────────────────────────────────? AppDayStat
                    │ (告警数据源)  │                                    (应用天统计)
                    └──────────────┘
```

---

## 3. 客户端架构

### 3.1 StarTracer 核心组件

`StarTracer` 是星尘监控客户端的核心实现，继承自 `DefaultTracer`，位于 `Stardust\Monitors\StarTracer.cs`。

#### 3.1.1 核心职责

| 职责 | 说明 |
|------|------|
| 自动埋点 | 通过 DI 注入后，自动为 DB/Redis/HTTP/WebAPI 等建立埋点 |
| 本地统计 | 在采样周期内收集调用次数、耗时、错误等统计信息 |
| 数据上报 | 通过 `ProcessSpans()` 将统计数据上传到星尘服务端 |
| 参数同步 | 接收服务端下发的采样参数（周期、采样数等） |

#### 3.1.2 关键配置参数

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `Period` | 60秒 | 采样周期，每周期上报一次 |
| `MaxSamples` | 1 | 每周期正常采样数 |
| `MaxErrors` | 10 | 每周期异常采样数 |
| `MaxFails` | 2880 | 最大失败队列长度（约2天） |
| `TrimSelf` | true | 剔除埋点上报自身的调用 |
| `EnableMeter` | true | 是否收集应用性能信息 |

#### 3.1.3 数据上报流程

```csharp
// StarTracer.ProcessSpans() 核心逻辑
protected override void ProcessSpans(ISpanBuilder[] builders)
{
    // 1. 剔除排除项（Excludes配置 + 上报自身）
    builders = builders.Where(e => !Excludes.Any(y => y.IsMatch(e.Name))).ToArray();
    builders = builders.Where(e => !e.Name.EndsWithIgnoreCase("/Trace/Report")).ToArray();
    
    // 2. 构建上报模型
    var model = new TraceModel
    {
        AppId = AppId,
        ClientId = ClientId,  // IP@ProcessId
        Builders = builders,   // 50~60个 SpanBuilder
        Info = _appInfo        // 应用性能信息（可选）
    };
    
    // 3. 根据数据大小选择上报方式
    var body = model.ToJson();
    var rs = body.Length > 1024 ?
        client.Invoke<TraceResponse>("Trace/ReportRaw", body.GetBytes()) :  // GZip压缩
        client.Invoke<TraceResponse>("Trace/Report", model);                 // 普通JSON
    
    // 4. 同步服务端参数
    if (rs != null)
    {
        Period = rs.Period;
        MaxSamples = rs.MaxSamples;
        // ...
    }
}
```

#### 3.1.4 上报数据结构

每个 `SpanBuilder` 包含该埋点在本周期内的统计信息：

```json
{
  "Name": "/api/user/info",     // 埋点名称
  "StartTime": 1234567890000,   // 周期开始时间(Unix毫秒)
  "EndTime": 1234567950000,     // 周期结束时间
  "Total": 1000,                // 本周期调用总次数
  "Errors": 5,                  // 错误次数
  "TotalCost": 15000,           // 总耗时(毫秒)
  "MaxCost": 200,               // 最大耗时
  "MinCost": 5,                 // 最小耗时
  "Samples": [...],             // 正常采样（默认1条）
  "ErrorSamples": [...]         // 异常采样（默认10条）
}
```

**关键理解**：客户端在本地已完成统计汇总，一个埋点在一个周期内无论调用 1000 次还是 10000 次，都只上报一条 SpanBuilder。

---

## 4. 服务端架构

### 4.1 TraceController 数据接收

位于 `Stardust.Server\Controllers\TraceController.cs`，负责接收和处理客户端上报的埋点数据。

#### 4.1.1 接口定义

| 接口 | 方法 | 说明 |
|------|------|------|
| `/Trace/Report` | POST | 接收普通埋点数据（JSON） |
| `/Trace/ReportRaw` | POST | 接收压缩后的大数据量（GZip） |

#### 4.1.2 ProcessData 核心处理流程

```csharp
private void ProcessData(AppTracer app, TraceModel model, Int32 nodeId, String ip, ISpanBuilder[] builders)
{
    var traces = new List<TraceData>();
    var samples = new List<SampleData>();
    
    foreach (var item in builders)
    {
        // ===== 第一阶段：数据过滤 =====
        
        // 1. 跟踪规则黑名单检查
        var rule = TraceRule.Match(item.Name);
        if (rule != null && !rule.IsWhite) continue;
        
        // 2. 应用排除项检查
        if (excludes.Any(e => e.IsMatch(item.Name))) continue;
        
        // 3. 时间范围检查（拒收超期/未来数据）
        var timestamp = item.StartTime.ToDateTime().ToLocalTime();
        if (timestamp < startTime || timestamp > endTime) continue;
        
        // 4. 名称长度检查
        if (item.Name.Length > TraceData._.Name.Length) continue;
        
        // ===== 第二阶段：获取跟踪项 =====
        
        // ?? 性能瓶颈点：GetOrAddItem
        var ti = cacheProvider.InnerCache.Get<TraceItem>(key);
        ti ??= app.GetOrAddItem(item.Name, rule?.IsWhite);
        cacheProvider.InnerCache.Set(key, ti, 600);  // 缓存10分钟
        
        if (!ti.Enable) continue;
        
        // ===== 第三阶段：生成入库数据 =====
        
        // 生成跟踪数据
        var td = TraceData.Create(item);
        td.AppId = app.ID;
        td.ItemId = ti.Id;
        traces.Add(td);
        
        // 生成采样数据
        samples.AddRange(SampleData.Create(td, item.Samples, true));
        samples.AddRange(SampleData.Create(td, item.ErrorSamples, false));
        
        // 超时处理（累加到错误数）
        if (timeout > 0 && item.Samples != null)
            td.Errors += item.Samples.Count(e => e.EndTime - e.StartTime > timeout);
    }
    
    // ===== 第四阶段：批量入库 =====
    traces.Insert(true);   // 支持自动分表
    samples.Insert(true);
    
    // ===== 第五阶段：加入统计队列 =====
    stat.Add(traces);                           // TraceStatService
    appStat.Add(now.Date);                      // AppDayStatService
    itemStat.Add(app.ID);                       // TraceItemStatService
}
```

#### 4.1.3 GetOrAddItem 性能分析

`GetOrAddItem` 是已知的性能瓶颈点，位于 `应用跟踪器.Biz.cs`：

```csharp
public TraceItem GetOrAddItem(String name, Boolean? whiteOnApi = null)
{
    // 1. 先在有效集合中查找（内存）
    var list = TraceItems;  // 缓存的有效跟踪项列表
    var ti = list.FirstOrDefault(e => e.Name.EqualIgnoreCase(name));
    if (ti != null) return ti;
    
    // 2. 再查全量字典（内存）
    var dic = _full ??= TraceItem.FindAllByApp(ID)
        .ToDictionary(e => e.Name, e => e, StringComparer.OrdinalIgnoreCase);
    if (dic.TryGetValue(name, out ti)) return ti;
    
    // 3. 规则匹配（可能较慢）
    ti = list.FirstOrDefault(e => !e.Cloned && e.IsMatch(name));
    ti ??= dic.Values.FirstOrDefault(e => !e.Cloned && e.IsMatch(name));
    if (ti != null) return ti;
    
    // 4. 新建跟踪项（数据库操作）
    ti = new TraceItem { AppId = ID, Name = name, Enable = ... };
    ti.Insert();
    list.Add(ti);
    
    return ti;
}
```

**性能问题**：
- 全量字典加载在首次访问时触发，可能阻塞
- 规则匹配需要遍历列表
- 新建跟踪项涉及数据库 INSERT
- 当前已有10分钟缓存机制缓解

### 4.2 TraceStatService 统计服务

位于 `Stardust.Server\Services\TraceStatService.cs`，是星尘服务端的**核心性能瓶颈**，占用约 80% 的服务器资源。

#### 4.2.1 统计架构

```
                         ┌──────────────────────────────────────┐
                         │         TraceStatService             │
                         │                                      │
                         │  ┌────────────────────────────────┐  │
                         │  │      内存队列 (_queue)          │  │
   TraceData ──────────? │  │   ConcurrentQueue<TraceData>   │  │
   (批量添加)            │  │   限制: 100,000 条             │  │
                         │  └────────────────────────────────┘  │
                         │                 │                    │
                         │     ┌───────────┴───────────┐        │
                         │                                    │
                         │  ┌──────────┐         ┌──────────┐   │
                         │  │ 流式计算  │         │ 批量计算  │   │
                         │  │ 5秒周期  │         │ 30秒周期 │   │
                         │  │DoFlowStat│         │DoBatchStat│  │
                         │  └──────────┘         └──────────┘   │
                         │                                      │
                         └──────────────────────────────────────┘
```

#### 4.2.2 双模式统计策略（已优化）

| 模式 | 周期 | 方法 | 说明 |
|------|------|------|------|
| 流式计算 | **30秒** | `DoFlowStat()` | 增量累加，仅计算分钟级统计 |
| 批量计算 | **60秒** | `DoBatchStat()` | 覆盖计算，处理小时/天级统计 |

**流式计算（DoFlowStat）**：
- 从队列中取出 TraceData
- **仅更新分钟级统计**（TraceMinuteStat + AppMinuteStat），用于告警
- 每次最多处理 100,000 条
- 使用延迟队列（EntityDeferredQueue）批量更新数据库

**批量计算（DoBatchStat）**：
- 根据时间维度重新计算
- 从下级统计表聚合到上级（小时/天统计）
- 用于修正流式计算的偏差

**延迟队列配置（已优化）**：
| 队列 | 周期 | 说明 |
|------|------|------|
| MinuteQueue | 120秒 | 分钟统计，告警数据源，需要较高实时性 |
| AppMinuteQueue | 120秒 | 应用分钟统计，同上 |
| HourQueue | 180秒 | 小时统计，实时性要求低 |
| DayQueue | 180秒 | 天统计，实时性要求低 |

#### 4.2.3 多级统计汇总

```
原始数据 TraceData
    │
    │ (流式增量 + 批量覆盖)
    
┌───────────────────────────────────────────────────────────────────────────┐
│                           分钟级统计 (5分钟粒度)                           │
│  TraceMinuteStat: 每应用每埋点每5分钟一行                                  │
│  AppMinuteStat: 每应用每5分钟一行 (用于告警)                               │
│  每天数据量: < 200万行 (10万埋点 × 288个5分钟周期，实际远小于此)           │
└───────────────────────────────────────────────────────────────────────────┘
    │
    │ (批量聚合)
    
┌───────────────────────────────────────────────────────────────────────────┐
│                           小时级统计                                       │
│  TraceHourStat: 每应用每埋点每小时一行                                     │
│  由 TraceMinuteStat 聚合生成                                               │
└───────────────────────────────────────────────────────────────────────────┘
    │
    │ (批量聚合)
    
┌───────────────────────────────────────────────────────────────────────────┐
│                           天级统计                                         │
│  TraceDayStat: 每应用每埋点每天一行                                        │
│  AppDayStat: 每应用每天一行 (衡量应用压力负载)                             │
│  由 TraceHourStat 聚合生成                                                 │
└───────────────────────────────────────────────────────────────────────────┘
```

#### 4.2.4 统计字段说明

每级统计都包含以下核心指标：

| 字段 | 类型 | 说明 |
|------|------|------|
| `Total` | Int64 | 调用总次数 |
| `Errors` | Int64 | 错误次数 |
| `TotalCost` | Int64 | 总耗时（毫秒） |
| `MaxCost` | Int32 | 最大耗时 |
| `MinCost` | Int32 | 最小耗时 |
| `Cost` | Int32 | 平均耗时（TP99近似） |
| `TotalValue` | Int64 | 用户数值累计 |
| `RingRate` | Double | 环比（与昨日同期对比） |

**TP99 计算逻辑**：
```csharp
// 当调用次数 >= 50 时，去掉头部1%的最大值后计算平均
if (st.Total >= 50)
{
    var totalCost = st.TotalCost;
    var ms = vs.Select(e => e.MaxCost).OrderByDescending(e => e).ToList();
    var n = (Int32)Math.Round(st.Total * 0.01);
    for (var i = 0; i < n && i < ms.Count; i++)
    {
        totalCost -= ms[i];
    }
    st.Cost = (Int32)Math.Round((Double)totalCost / (st.Total - n));
}
```

#### 4.2.5 延迟队列机制

使用 `EntityDeferredQueue` 实现批量数据库更新：

```csharp
internal class MyQueue : EntityDeferredQueue
{
    public Int32 Period { get; set; } = 60;  // 60秒批量提交
    
    public override Int32 Process(IList<Object> list)
    {
        return list.Cast<IEntity>().Update();  // 批量UPDATE
    }
}
```

**队列类型**：
- `DayQueue`: 天统计延迟队列
- `HourQueue`: 小时统计延迟队列
- `MinuteQueue`: 分钟统计延迟队列
- `AppMinuteQueue`: 应用分钟统计延迟队列

### 4.3 AppDayStatService 应用天统计

位于 `Stardust.Server\Services\AppDayStatService.cs`，负责应用维度的天级统计。

#### 4.3.1 处理逻辑

```csharp
private void Process(DateTime date)
{
    // 1. 从 TraceDayStat 按应用分组聚合
    var list = TraceDayStat.SearchGroupAppAndType(date);
    
    // 2. 计算各类型调用量
    foreach (var group in list.GroupBy(e => e.AppId))
    {
        var st = AppDayStat.FindOrCreate(date, group.Key);
        st.Total = group.Sum(e => e.Total);
        st.Errors = group.Sum(e => e.Errors);
        
        // 分类统计
        st.Apis = group.Where(e => e.Type == "api").Sum(e => e.Total);
        st.Https = group.Where(e => e.Type == "http").Sum(e => e.Total);
        st.Dbs = group.Where(e => e.Type == "db").Sum(e => e.Total);
        st.Mqs = group.Where(e => e.Type == "mq").Sum(e => e.Total);
        st.Redis = group.Where(e => e.Type == "redis").Sum(e => e.Total);
        
        // 计算环比
        var yesterday = AppDayStat.Find(date.AddDays(-1), group.Key);
        st.RingRate = yesterday?.Total > 0 ? (Double)st.Total / yesterday.Total : 1;
        
        st.Save();
    }
}
```

---

## 5. 数据存储

### 5.1 数据库选型

| 数据库 | 使用场景 |
|--------|----------|
| MySQL | 生产环境主库 |
| SQLite | 小规模部署/测试 |

**典型配置**：
- 低配：4核8G
- 推荐：16核32G

### 5.2 核心数据表

#### 5.2.1 数据表概览

| 表名 | 说明 | 分表策略 | 每日数据量 |
|------|------|----------|-----------|
| `TraceData` | 跟踪数据（原始） | 31张表（按天） | 2000~5000万行 |
| `SampleData` | 采样数据（明细） | 31张表（按天） | 几千万行 |
| `TraceMinuteStat` | 分钟统计 | 无 | < 200万行 |
| `TraceHourStat` | 小时统计 | 无 | < 20万行 |
| `TraceDayStat` | 天统计 | 无 | < 10万行 |
| `AppMinuteStat` | 应用分钟统计 | 无 | < 3万行 |
| `AppDayStat` | 应用天统计 | 无 | < 100行 |
| `TraceItem` | 跟踪项（埋点定义） | 无 | < 10万行 |
| `AppTracer` | 应用跟踪器配置 | 无 | < 1000行 |

#### 5.2.2 分表策略

`TraceData` 和 `SampleData` 采用按天分表：

```csharp
// TraceData.cs
static TraceData()
{
    Meta.ShardPolicy = new TimeShardPolicy(nameof(Id), Meta.Factory)
    {
        TablePolicy = "{0}_{1:dd}",  // 如 TraceData_01, TraceData_02, ...
        Step = TimeSpan.FromDays(1),
    };
}
```

**分表优势**：
- 31张表循环使用
- 便于数据清理（直接 TRUNCATE 过期表）
- 避免单表过大

#### 5.2.3 数据保留策略

| 保留天数 | 适用场景 |
|---------|---------|
| 3~7天 | 数据库压力大 |
| 7~15天 | 标准配置 |
| 15~30天 | 高配环境 |

### 5.3 数据库优化

#### 5.3.1 MySQL 压缩表

```csharp
// TraceData 启用压缩表
var table = Meta.Table.DataTable;
table.Properties["ROW_FORMAT"] = "COMPRESSED";
table.Properties["KEY_BLOCK_SIZE"] = "4";
```

#### 5.3.2 XCode 累加字段

统计表使用累加字段减少锁竞争：

```csharp
// TraceMinuteStat.cs
static TraceMinuteStat()
{
    var df = Meta.Factory.AdditionalFields;
    df.Add(nameof(Total));
    df.Add(nameof(Errors));
    df.Add(nameof(TotalCost));
    // 生成 SQL: UPDATE ... SET Total=Total+@Total ...
}
```

---

## 6. 性能分析

### 6.1 实际运行指标

基于生产环境数据收集：

| 指标 | 实际值 | 说明 |
|------|--------|------|
| _queue 队列积压 | < 1000 条 | 远低于10万限制，流式计算压力不大 |
| 批量计算修正能力 | 完全修正 | 可以更激进地优化流式计算 |
| 告警延迟容忍度 | 3~5 分钟 | 统计频率可大幅降低 |
| 统计数据查看率 | < 1% | 99%+ 数据无人查看 |

### 6.2 性能瓶颈点

#### 6.2.1 延迟队列 UPDATE（**主要瓶颈**）

**问题**：4个延迟队列频繁批量提交，产生大量 UPDATE 操作
**原因**：统计表的频繁更新导致数据库 CPU 和 IO 都很高
**已优化**：
- 延长队列提交周期（60秒 → 120~180秒）
- 流式计算仅更新分钟级统计，小时/天级交给批量计算

#### 6.2.2 流式计算频率（已优化）

**问题**：原来每5秒执行一次，队列积压却只有1000条
**已优化**：调整为每30秒执行一次，减少 83% 的计算频率

#### 6.2.3 GetOrAddItem（中等）

**问题**：每次上报都需要查找/创建跟踪项
**现状**：已有 10 分钟缓存
**优化空间**：
- 延长缓存时间
- 预热常用跟踪项

### 6.3 优化效果预估

| 指标 | 优化前 | 优化后 | 改善 |
|------|--------|--------|------|
| 流式计算频率 | 每5秒 | 每30秒 | -83% |
| 批量计算频率 | 每30秒 | 每60秒 | -50% |
| 延迟队列提交 | 每60秒 | 每120~180秒 | -50~67% |
| 流式计算维度 | 4个（天/时/分/应用分） | 2个（分/应用分） | -50% |
| 预计CPU占用 | 80%+ | 30%- | -60% |
| 预计数据库IO | 高 | 低 | -60% |

### 6.4 并发估算

| 指标 | 数值 | 说明 |
|------|------|------|
| 在线应用 | 100个 | 典型企业规模 |
| 应用实例 | 200个 | 平均每应用2实例 |
| 上报频率 | 60秒/次 | 默认配置 |
| 并发上报 | ~3.3个/秒 | 200/60 |
| 每次SpanBuilder | 50~60个 | 平均估计 |
| 每秒TraceData | ~200条 | 3.3 × 60 |

**结论**：并发压力不大，主要瓶颈在统计服务的数据库 UPDATE 操作。

---

## 7. 优化方向

### 7.1 已实施的优化

#### 7.1.1 参数调优

```csharp
// TraceStatService.cs 优化后配置
public Int32 FlowPeriod { get; set; } = 30;      // 5秒 → 30秒
public Int32 BatchPeriod { get; set; } = 60;     // 30秒 → 60秒

private readonly DayQueue _dayQueue = new() { Period = 180 };      // 60秒 → 180秒
private readonly HourQueue _hourQueue = new() { Period = 180 };    // 60秒 → 180秒
private readonly MinuteQueue _minuteQueue = new() { Period = 120 }; // 60秒 → 120秒
private readonly AppMinuteQueue _appMinuteQueue = new() { Period = 120 }; // 60秒 → 120秒
```

#### 7.1.2 流式计算精简

流式计算（DoFlowStat）仅更新分钟级统计，小时/天级统计由批量计算处理：
- **保留**：TraceMinuteStat、AppMinuteStat（告警数据源）
- **移除**：TraceHourStat、TraceDayStat（由批量计算覆盖）

### 7.2 后续优化方向

#### 7.2.1 按需计算方案

**核心思路**：有人查看统计数据时才加速计算

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                            Stardust.Web (管理端)                            │
├─────────────────────────────────────────────────────────────────────────────┤
│  用户访问应用A统计页面                                                       │
│         │                                                                    │
│                                                                             │
│  广播关注事件 (每分钟2次)                                                    │
│  { AppId: A, FocusExpire: 5分钟 }                                           │
│         │                                                                    │
└─────────┼───────────────────────────────────────────────────────────────────┘
          │
          
┌─────────────────────────────────────────────────────────────────────────────┐
│                         Stardust.Server (服务端)                            │
├─────────────────────────────────────────────────────────────────────────────┤
│  TraceStatService                                                           │
│         │                                                                    │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────┐           │
│  │  关注列表                                                    │           │
│  │  { AppId: A, ExpireTime: now+5min, Priority: High }        │           │
│  └─────────────────────────────────────────────────────────────┘           │
│         │                                                                    │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────┐           │
│  │  统计调度策略                                                │           │
│  │  - 高优先级应用：每5秒统计                                   │           │
│  │  - 普通应用：每5分钟统计                                     │           │
│  │  - 低活跃应用：每15分钟统计                                  │           │
│  └─────────────────────────────────────────────────────────────┘           │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

**预期效果**：
- 用户关注的应用：实时性高（5秒级）
- 其他应用：降低频率（5~15分钟）
- 整体 CPU 下降 50%+

#### 7.1.2 告警与实时性平衡

**约束条件**：
- 客户端上报周期：60秒
- 告警可接受延迟：1~3分钟
- 统计计算频率：不应低于1分钟（否则意义不大）

**建议方案**：
- 默认统计周期：5分钟
- 有告警配置的应用/埋点：1分钟
- 用户正在查看：5秒

### 7.2 GetOrAddItem 优化

#### 7.2.1 扩展缓存策略

```csharp
// 当前：10分钟缓存
cacheProvider.InnerCache.Set(key, ti, 600);

// 优化：延长到30分钟或1小时
cacheProvider.InnerCache.Set(key, ti, 1800);

// 进一步：使用二级缓存
// L1: 本地内存（快速）
// L2: 分布式缓存（共享）
```

#### 7.2.2 批量预热

```csharp
// 在应用首次上报时，预热该应用的所有跟踪项
public void PreloadItems(Int32 appId)
{
    var items = TraceItem.FindAllByApp(appId);
    foreach (var item in items)
    {
        var key = $"trace:Item:{appId}-{item.Name}";
        cacheProvider.InnerCache.Set(key, item, 1800);
    }
}
```

### 7.3 数据库优化

#### 7.3.1 批量操作合并

```csharp
// 当前：单条 UPDATE
st.Update();

// 优化：批量 UPDATE（已有 EntityDeferredQueue）
// 延长 Period 从 60秒 到 120秒
_dayQueue = new DayQueue { Period = 120 };
```

#### 7.3.2 内存聚合

```csharp
// 在内存中聚合更多数据后再写入
// 减少数据库写入频率
public class AggregatedStatQueue
{
    private readonly Dictionary<String, TraceDayStat> _buffer = new();
    private DateTime _lastFlush = DateTime.Now;
    
    public void Add(TraceDayStat stat)
    {
        var key = stat.Key;
        if (_buffer.TryGetValue(key, out var existing))
        {
            existing.Total += stat.Total;
            existing.Errors += stat.Errors;
            // ... 合并其他字段
        }
        else
        {
            _buffer[key] = stat;
        }
        
        // 每2分钟或缓冲区超过1000条时刷新
        if (DateTime.Now - _lastFlush > TimeSpan.FromMinutes(2) || _buffer.Count > 1000)
        {
            Flush();
        }
    }
    
    private void Flush()
    {
        var list = _buffer.Values.ToList();
        _buffer.Clear();
        list.Update();  // 批量UPDATE
        _lastFlush = DateTime.Now;
    }
}
```

---

## 8. 已确认信息

根据生产环境数据和运维经验，以下问题已确认：

| 问题 | 确认结果 | 影响 |
|------|---------|------|
| 队列积压情况 | < 1000 条，极少达到10万 | 流式计算压力不大 |
| 批量计算准确性 | 能完全修正流式计算偏差 | 可激进优化流式计算 |
| 告警延迟容忍度 | 3~5 分钟 | 统计频率可大幅降低 |
| 统计数据查看率 | 99%+ 无人查看 | 适合按需计算 |
| 主要性能瓶颈 | 延迟队列 UPDATE 操作 | 重点优化方向 |

---

## 9. 附录

### 9.1 关键代码位置

| 功能 | 文件路径 |
|------|---------|
| 客户端核心 | `Stardust\Monitors\StarTracer.cs` |
| 服务端接收 | `Stardust.Server\Controllers\TraceController.cs` |
| 追踪统计服务 | `Stardust.Server\Services\TraceStatService.cs` |
| 应用天统计服务 | `Stardust.Server\Services\AppDayStatService.cs` |
| 应用跟踪器 | `Stardust.Data\Monitors\应用跟踪器.Biz.cs` |
| 跟踪数据实体 | `Stardust.Data\Monitors\跟踪数据.Biz.cs` |
| 分钟统计实体 | `Stardust.Data\Monitors\跟踪分钟统计.Biz.cs` |

### 9.2 相关文档

- [链路追踪 ITracer 接口规范](../NewLife.Core/Doc/链路追踪ITracer.md)
- [星尘监控性能优化方案](星尘监控性能优化方案.md)
- [星尘分布式服务平台](https://newlifex.com/blood/stardust)

### 9.3 版本历史

| 版本 | 日期 | 说明 |
|------|------|------|
| v1.0 | 2026-02-03 | 初始架构文档 |
| v1.1 | 2026-02-03 | 性能优化：调整统计参数，精简流式计算 |

---

## 10. 后续计划

1. ? **参数优化**：调整流式/批量计算周期和延迟队列提交周期
2. ? **流式计算精简**：仅计算分钟级统计，小时/天级交给批量计算
3. ?? **监控指标**：增加队列长度、计算耗时等监控
4. ?? **按需计算**：实现用户关注应用的加速计算
5. ?? **验证效果**：部署后观察 CPU 和数据库 IO 下降情况
